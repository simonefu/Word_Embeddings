{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "weird-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.it import Italian\n",
    "import re\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from tqdm import tqdm\n",
    "nlp = spacy.load(\"it_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wooden-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dir = '../wiki_clean'\n",
    "\n",
    "texts = list()\n",
    "\n",
    "sub_dir = 'AA'\n",
    "n_id_doc = '00'\n",
    "\n",
    "with open(f'{path_dir}/{sub_dir}/wiki_{n_id_doc}') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "for line in tqdm(lines):\n",
    "    if (len(line) > 3) & ( not '<doc' in line):\n",
    "        doc = nlp(line)\n",
    "        words = [t.text.lower() for t in doc if t.text not in ['\\n', ',', ':', '.', '(', ')']]\n",
    "        texts.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "secure-robert",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5284/5284 [00:49<00:00, 107.58it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"file.txt\", 'w') as output:\n",
    "    for row in texts:\n",
    "        output.write(str(row) + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ecological-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation in python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "rural-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import Corpus, Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "continued-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "olympic-capacity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5284/5284 [00:49<00:00, 106.71it/s]\n"
     ]
    }
   ],
   "source": [
    "path_dir = '../wiki_clean'\n",
    "\n",
    "texts = list()\n",
    "\n",
    "sub_dir = 'AA'\n",
    "n_id_doc = '00'\n",
    "\n",
    "with open(f'{path_dir}/{sub_dir}/wiki_{n_id_doc}') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "texts = list()\n",
    "\n",
    "for line in tqdm(lines):\n",
    "    if (len(line) > 3) & ( not '<doc' in line):\n",
    "        doc = nlp(line)\n",
    "        words = [t.text.lower() for t in doc if t.text not in ['\\n']]\n",
    "        texts.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "facial-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.fit(texts, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "final-pepper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    }
   ],
   "source": [
    "glove = Glove(no_components=20, learning_rate=0.05)\n",
    "\n",
    "glove.fit(corpus.matrix, epochs=30, no_threads=1, verbose=True)\n",
    "glove.add_dictionary(corpus.dictionary)\n",
    "glove.save('glove.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "portable-arthritis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01254653 0.12425569 0.08058729 0.02231477 0.05665893]\n"
     ]
    }
   ],
   "source": [
    "# print the vector associated to the given word (tecnologico in this case)\n",
    "print(glove.word_vectors[glove.dictionary['tecnologico']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "structural-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('doppia', 0.9911683207222267),\n",
       " ('decretarono', 0.9896572661099656),\n",
       " ('ostacolo', 0.9838379768242017)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the most similar words (the top 4 ranked in this case) \n",
    "glove.most_similar('tecnologico', number=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
